{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qPKYjF5N1sp"
      },
      "source": [
        "# \"Quora Questions Pairs using BERT\"\n",
        "> \"Task: Identify wether two question have similar context/meaning or not\"\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [fastpages, jupyter]\n",
        "- image: images/some_folder/your_image.png\n",
        "- hide: false\n",
        "- search_exclude: true\n",
        "- metadata_key1: metadata_value1\n",
        "- metadata_key2: metadata_value2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDHKLvx7CU6U"
      },
      "source": [
        "### Quora Questions Pairs using BERT : Overview\n",
        "\n",
        "**Task: Identify wether two question have similar context/meaning or not**<br>\n",
        "[kaggle](https://www.kaggle.com/c/quora-question-pairs/overview)\n",
        "<br>\n",
        "I have tried this problem using two different approach\n",
        "\n",
        "\n",
        "1.   Using Naive Bayes Classifier\n",
        "2.   Using BERT\n",
        "\n",
        "### Naive Bayes Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlQy8-Hekb5q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "path = \"/content/drive/MyDrive/Quora Questions NLP\"\n",
        "nltk.download()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "K1JfbFe3koUP",
        "outputId": "4b58a1f8-bc04-45b3-cc99-6203ca8c3f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 404290\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "5   5    11  ...  I'm a triple Capricorn (Sun, Moon and ascendan...            1\n",
              "6   6    13  ...  What keeps childern active and far from phone ...            0\n",
              "7   7    15  ...          What should I do to be a great geologist?            1\n",
              "8   8    17  ...              When do you use \"&\" instead of \"and\"?            0\n",
              "9   9    19  ...  How do I hack Motorola DCX3400 for free internet?            0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load Data\n",
        "train = pd.read_csv(path+\"/train.csv\")\n",
        "print(\"Total samples:\",len(train))\n",
        "train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPLogC5t22AY",
        "outputId": "20c4587e-6c88-4d8a-a056-84fab8943b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id              0\n",
            "qid1            0\n",
            "qid2            0\n",
            "question1       1\n",
            "question2       2\n",
            "is_duplicate    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(train.isnull().sum(axis=0))#dropping null values\n",
        "train.dropna(axis=0,inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY9wDKyOFDlT"
      },
      "source": [
        "#### Text Preprocessing\n",
        "\n",
        "\n",
        "*   Remove stop words\n",
        "*   Lemmatize \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9r3xbLrm_RN"
      },
      "outputs": [],
      "source": [
        "#preprocessing\n",
        "def preprocess(series):\n",
        "  #remove characters other than alphabets & numerics\n",
        "  words = re.sub(\"[^A-Za-z0-9]\",\" \",series).lower().split()\n",
        "\n",
        "  #lemmatize words\n",
        "  lemm = WordNetLemmatizer()\n",
        "  stpwords = stopwords.words('english')\n",
        "  lemmitized = [lemm.lemmatize(word) for word in words if word not in stpwords]\n",
        "  sent = ' '.join(lemmitized)\n",
        "  return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri99TQVMoHEg"
      },
      "outputs": [],
      "source": [
        "\n",
        "train['question1'] =train['question1'].apply(preprocess)#Apply preprocessing\n",
        "train['question2'] =train['question2'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "yNu_DueBwY3i",
        "outputId": "a217b3f0-4ce8-4609-8a52-a75ea31c683b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>combine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Should I buy tiago? What keeps childern active...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "      <td>How can I be a good geologist? What should I d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "      <td>When do you use シ instead of し? When do you us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...  is_duplicate                                            combine\n",
              "0   0     1  ...             0  What is the step by step guide to invest in sh...\n",
              "1   1     3  ...             0  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
              "2   2     5  ...             0  How can I increase the speed of my internet co...\n",
              "3   3     7  ...             0  Why am I mentally very lonely? How can I solve...\n",
              "4   4     9  ...             0  Which one dissolve in water quikly sugar, salt...\n",
              "5   5    11  ...             1  Astrology: I am a Capricorn Sun Cap moon and c...\n",
              "6   6    13  ...             0  Should I buy tiago? What keeps childern active...\n",
              "7   7    15  ...             1  How can I be a good geologist? What should I d...\n",
              "8   8    17  ...             0  When do you use シ instead of し? When do you us...\n",
              "9   9    19  ...             0  Motorola (company): Can I hack my Charter Moto...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "def concat(ser):#concatenate Question 1 & Question 2\n",
        "  print(ser['question1'])\n",
        "  return 1\n",
        "train['combine'] = train.apply(lambda ser: ser['question1'] + \" \" + ser['question2'],axis=1)\n",
        "train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30WPiRB9FlHI"
      },
      "source": [
        "#### Convert Words into Vector\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KipLu4QmoViN",
        "outputId": "3d092751-9e59-4ae3-f6c8-b9d39921cd71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(404287, 50000)\n",
            "(384072, 50000) (20215, 50000)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cv = TfidfVectorizer(max_features=50000)#Word to Vectors using Tf-Idf\n",
        "\n",
        "#Take combine questions data as X\n",
        "X = cv.fit_transform(train['combine'])\n",
        "y = np.array(train['is_duplicate'])\n",
        "print(X.shape)\n",
        "\n",
        "#Tarin-Test Spilt\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05)\n",
        "print(X_train.shape,X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hILRi5S4AokT"
      },
      "outputs": [],
      "source": [
        "\n",
        "naive_model = MultinomialNB()#Training\n",
        "naive_model.fit(X_train,y_train)\n",
        "\n",
        "#Predictions\n",
        "y_pred_train = naive_model.predict(X_train)\n",
        "y_pred_test = naive_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkhT6SwUwHSt",
        "outputId": "7ba8188f-b390-42f4-d014-d78e1c36c4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7558140140390344 0.7431610190452634\n"
          ]
        }
      ],
      "source": [
        " \n",
        "accuracy_train = sum((y_pred_train == y_train).astype(int))/len(y_train)\n",
        "accuracy_test = sum((y_pred_test == y_test).astype(int))/len(y_test)\n",
        "print(accuracy_train,accuracy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRRwz7I3JJRr"
      },
      "source": [
        "We got 74% Accuracy which is very bad for binary classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8caSnoaJR2A"
      },
      "source": [
        "### BERT\n",
        "I have used \"Semantic Similarity with BERT\" code to solve this problem.<br>\n",
        "reference : https://keras.io/examples/nlp/semantic_similarity_with_bert/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8JzKW4bBuT4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "!pip install transformers==2.11.0\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz9AA6PaNLig"
      },
      "outputs": [],
      "source": [
        "max_length = 128  # Maximum length of input sentence to the model.\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "# Labels in our dataset.\n",
        "labels = [1,0]\n",
        "#1 : Non Duplicate\n",
        "#0 : Duplicate\n",
        "df = pd.read_csv(path+\"/train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqCjQXp7KYeE"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5OjhdncStr-",
        "outputId": "3c9c603e-b9a6-4f8a-dd89-0967d56a72d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id              0\n",
            "qid1            0\n",
            "qid2            0\n",
            "question1       1\n",
            "question2       2\n",
            "is_duplicate    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(df.isnull().sum(axis=0))#Dropiing Null values\n",
        "df.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "MyVkSGoNNaqY",
        "outputId": "0891bfe7-27c2-48ab-a11c-d3c1c7e50abe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>Method to find separation of slits using fresn...</td>\n",
              "      <td>What are some of the things technicians can te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>79</td>\n",
              "      <td>80</td>\n",
              "      <td>What is the stall speed and AOA of an f-14 wit...</td>\n",
              "      <td>Why did aircraft stop using variable-sweep win...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>127</td>\n",
              "      <td>128</td>\n",
              "      <td>Why do I always get depressed?</td>\n",
              "      <td>Why do I always get depressed in the evening?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>64</td>\n",
              "      <td>129</td>\n",
              "      <td>130</td>\n",
              "      <td>Where can I find a European family office data...</td>\n",
              "      <td>Where do I find a U.S. family office database?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  qid1  ...                                          question2 is_duplicate\n",
              "1    1     3  ...  What would happen if the Indian government sto...            0\n",
              "10  10    21  ...  What are some of the things technicians can te...            0\n",
              "39  39    79  ...  Why did aircraft stop using variable-sweep win...            0\n",
              "63  63   127  ...      Why do I always get depressed in the evening?            0\n",
              "64  64   129  ...     Where do I find a U.S. family office database?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create mask for train-test distribution\n",
        "mask = np.random.rand(len(df)) < 0.7\n",
        "train_df = df[mask]\n",
        "not_train = df[~mask]\n",
        "\n",
        "#create mask for val-test distribution\n",
        "mask = np.random.rand(len(not_train)) < 0.5\n",
        "test_df = not_train[mask]\n",
        "val_df = not_train[~mask]\n",
        "val_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HYhifpvPWR4",
        "outputId": "2a3dc6f7-9890-4e09-e0c9-357b6f149b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total train samples : 282550\n",
            "Total validation samples: 60634\n",
            "Total test samples: 61103\n"
          ]
        }
      ],
      "source": [
        "# Shape of the data\n",
        "print(f\"Total train samples : {train_df.shape[0]}\")\n",
        "print(f\"Total validation samples: {val_df.shape[0]}\")\n",
        "print(f\"Total test samples: {test_df.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P4qgJk-OrNg",
        "outputId": "c3a4705d-dcf1-4eba-b69a-a9f4ea315401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Target Distribution\n",
            "0    178627\n",
            "1    103923\n",
            "Name: is_duplicate, dtype: int64\n",
            "Validation Target Distribution\n",
            "0    38030\n",
            "1    22604\n",
            "Name: is_duplicate, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Target Distribution\")\n",
        "print(train_df.is_duplicate.value_counts())\n",
        "\n",
        "print(\"Validation Target Distribution\")\n",
        "print(val_df.is_duplicate.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4AU_fSSTp-W",
        "outputId": "ff6ca75b-9650-4ab9-9a91-bdc7256f1c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train.shape:(282550, 2)\n",
            "y_val.shape:(60634, 2)\n",
            "y_test.shape:(61103, 2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_train = tf.keras.utils.to_categorical(train_df.is_duplicate, num_classes=2)#One hot encodding representation\n",
        "print(f\"y_train.shape:{y_train.shape}\")\n",
        "\n",
        "y_val = tf.keras.utils.to_categorical(val_df.is_duplicate, num_classes=2)\n",
        "print(f\"y_val.shape:{y_val.shape}\")\n",
        "\n",
        "y_test = tf.keras.utils.to_categorical(test_df.is_duplicate, num_classes=2)\n",
        "print(f\"y_test.shape:{y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_CjpwdrKSnG"
      },
      "source": [
        "#### Custom Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p83ejnitUOmx"
      },
      "outputs": [],
      "source": [
        "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generates batches of data.\n",
        "\n",
        "    Args:\n",
        "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
        "        labels: Array of labels.\n",
        "        batch_size: Integer batch size.\n",
        "        shuffle: boolean, whether to shuffle the data.\n",
        "        include_targets: boolean, whether to incude the labels.\n",
        "\n",
        "    Returns:\n",
        "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
        "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
        "         if `include_targets=False`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sentence_pairs,\n",
        "        labels,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        include_targets=True,\n",
        "    ):\n",
        "        self.sentence_pairs = sentence_pairs\n",
        "        self.labels = labels\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.include_targets = include_targets\n",
        "        \n",
        "        # Load our BERT Tokenizer to encode the text.\n",
        "        # We will use base-base-uncased pretrained model.\n",
        "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
        "            \"bert-base-uncased\", do_lower_case=True\n",
        "        )\n",
        "        self.indexes = np.arange(len(self.sentence_pairs))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch.\n",
        "        return len(self.sentence_pairs) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves the batch of index.\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        sentence_pairs = self.sentence_pairs[indexes]\n",
        "\n",
        "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
        "        # encoded together and separated by [SEP] token.\n",
        "        encoded = self.tokenizer.batch_encode_plus(\n",
        "            sentence_pairs.tolist(),\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors=\"tf\",\n",
        "        )\n",
        "\n",
        "        # Convert batch of encoded features to numpy array.\n",
        "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "        # Set to true if data generator is used for training/validation.\n",
        "        if self.include_targets:\n",
        "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
        "            return [input_ids, attention_masks, token_type_ids], labels\n",
        "        else:\n",
        "            return [input_ids, attention_masks, token_type_ids]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
        "        if self.shuffle:\n",
        "            np.random.RandomState(42).shuffle(self.indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7SenBveKsJm"
      },
      "source": [
        "#### Build The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-AaVCJnVZY4",
        "outputId": "25af4675-e9ed-4a24-fa5f-98213aacf079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "Strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fa42b661090>\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 128, 768), ( 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_masks[0][0]            \n",
            "                                                                 token_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 128, 128)     426496      tf_bert_model_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 256)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            514         dropout_75[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 109,909,250\n",
            "Trainable params: 427,010\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "strategy = tf.distribute.MirroredStrategy()# Create the model under a distribution strategy scope.\n",
        "\n",
        "with strategy.scope():\n",
        "    # Encoded token ids from BERT tokenizer.\n",
        "    input_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
        "    )\n",
        "    # Attention masks indicates to the model which tokens should be attended to.\n",
        "    attention_masks = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
        "    )\n",
        "    # Token type ids are binary masks identifying different sequences in the model.\n",
        "    token_type_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
        "    )\n",
        "    # Loading pretrained BERT model.\n",
        "    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
        "    bert_model.trainable = False\n",
        "\n",
        "    sequence_output, pooled_output = bert_model(\n",
        "        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
        "    )\n",
        "    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
        "    bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(sequence_output)\n",
        "    \n",
        "    # Applying hybrid pooling approach to bi_lstm sequence output.\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n",
        "    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n",
        "    dropout = tf.keras.layers.Dropout(0.3)(concat)\n",
        "    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n",
        "    model = tf.keras.models.Model(\n",
        "        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"acc\"],\n",
        "    )\n",
        "\n",
        "\n",
        "print(f\"Strategy: {strategy}\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGgQnzm5Kyu0"
      },
      "source": [
        "#### Create train and validation data generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "79c51534eee347cb8061845c9598a8b1",
            "6b2745d462b24a1581247aaf087c8c12",
            "3e82aee461924e348ed361f0d966d230",
            "404a3f9eb80649a49d905e38a31472df",
            "9f1f543b8caf4b56ad8ebc212a4b9bcf",
            "81845e5c98d24f26b1e349124db910bb",
            "603ab12269b545c8b16c6cbd2a679b22",
            "bc21b8ed339b486ea8d7e21ad0098577"
          ]
        },
        "id": "u0YYkAdWVzx9",
        "outputId": "aff7714f-cc9c-4bbe-ddce-2a8544fb6147"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79c51534eee347cb8061845c9598a8b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_data = BertSemanticDataGenerator(\n",
        "    train_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "val_data = BertSemanticDataGenerator(\n",
        "    val_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    y_val,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klXsKJVkK5ng"
      },
      "source": [
        "#### Train the model\n",
        "Training is done only for the top layers to perform \"feature extraction\", which will allow the model to use the representations of the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtddz2yOYh7J",
        "outputId": "b6a0622f-6697-4762-cd60-0cb379dcae70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "8850/8850 [==============================] - 3281s 366ms/step - loss: 0.4316 - acc: 0.7859 - val_loss: 0.3371 - val_acc: 0.8432\n",
            "Epoch 2/2\n",
            "8850/8850 [==============================] - 3229s 365ms/step - loss: 0.3474 - acc: 0.8382 - val_loss: 0.3269 - val_acc: 0.8474\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=epochs,\n",
        "     use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEbnhEX1CWRg"
      },
      "source": [
        "#### Fine Tuning\n",
        "\n",
        "Now BERT model has knowledge of Language & Context now we can unfreeze the BERT pretrained weights & retrain using very low learning rate to solve actual NLP problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPYy3UMICQN_",
        "outputId": "1b7904c1-e300-44ad-b974-87aecd58f16a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 128, 768), ( 109482240   input_ids[0][0]                  \n",
            "                                                                 attention_masks[0][0]            \n",
            "                                                                 token_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128, 128)     426496      tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
            "                                                                 global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            514         dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 109,909,250\n",
            "Trainable params: 109,909,250\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "bert_model.trainable = True\n",
        "# Recompile the model to make the change effective.\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-OHjA9aYwn7",
        "outputId": "93de2707-298a-497a-f6da-909a02635aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "8850/8850 [==============================] - 7739s 874ms/step - loss: 0.2853 - accuracy: 0.8741 - val_loss: 0.2712 - val_accuracy: 0.8832\n",
            "Epoch 2/2\n",
            "8850/8850 [==============================] - 7737s 874ms/step - loss: 0.2139 - accuracy: 0.9100 - val_loss: 0.2477 - val_accuracy: 0.8973\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=epochs,\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLjeRqvWMbyx"
      },
      "source": [
        "After Waiting of 4-5 hours nowour model is trained!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8sYaB-wCjDp"
      },
      "source": [
        "#### Evaluate on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1jV1ZuOChKi",
        "outputId": "675df007-775f-4781-9d6c-66a4ec8160a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1890/1890 [==============================] - 529s 280ms/step - loss: 0.2438 - accuracy: 0.9001\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.24381373822689056, 0.9000826478004456]"
            ]
          },
          "execution_count": 45,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = BertSemanticDataGenerator(\n",
        "    test_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    y_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "model.evaluate(test_data, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS6T3PSpLp5k"
      },
      "source": [
        "We Got 90% Accuracy on Test Dataset which is far better than Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uUn9RU2DcfB"
      },
      "outputs": [],
      "source": [
        "def check_similarity(sentence1, sentence2):\n",
        "  sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "  test_data = BertSemanticDataGenerator(\n",
        "      sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "  )\n",
        "\n",
        "  proba = model.predict(test_data)[0]\n",
        "  idx = np.argmax(proba)\n",
        "  proba = f\"{proba[idx]: .2f}%\"\n",
        "  pred = labels[idx]\n",
        "  return pred, proba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioYNFI58LfJL"
      },
      "source": [
        "#### Try the custom Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTA9J9gxOPtR",
        "outputId": "bd203aee-5ae4-4c2e-c47c-b96ac6fe0c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Why when I read an English article do I understand most of the words but I cannot understand the message of the article very well? How can I improve my reading comprehension?\n",
            "I am very poor in English language and even struggle to understand while reading small article also. How can I improve it without attend class?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0, ' 0.81%')"
            ]
          },
          "execution_count": 47,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ind = np.random.randint(0,500) \n",
        "#Duplicate Questions\n",
        "q1 = test_df[test_df[\"is_duplicate\"] == 1].iloc[ind]['question1']\n",
        "q2 = test_df[test_df[\"is_duplicate\"] == 1].iloc[ind]['question2']\n",
        "print(q1+\"\\n\"+q2)\n",
        "check_similarity(q1,q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NhfBIwGOZ2_",
        "outputId": "5fbddd45-b31f-459a-81f1-fd07cedcbe54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many pullups can an average person do?\n",
            "How many photos a day does an average person take with their phone.?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1, ' 1.00%')"
            ]
          },
          "execution_count": 44,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ind = np.random.randint(0,500)\n",
        "#Non-Duplicate Questions\n",
        "q1 = test_df[test_df[\"is_duplicate\"] == 0].iloc[ind]['question1']\n",
        "q2 = test_df[test_df[\"is_duplicate\"] == 0].iloc[ind]['question2']\n",
        "print(q1+\"\\n\"+q2)\n",
        "check_similarity(q1,q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1rr6dvgSmVL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT of Quora Questions Pairs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e82aee461924e348ed361f0d966d230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81845e5c98d24f26b1e349124db910bb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f1f543b8caf4b56ad8ebc212a4b9bcf",
            "value": 231508
          },
          "model_module_version": "1.5.0"
        },
        "404a3f9eb80649a49d905e38a31472df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc21b8ed339b486ea8d7e21ad0098577",
            "placeholder": "​",
            "style": "IPY_MODEL_603ab12269b545c8b16c6cbd2a679b22",
            "value": " 232k/232k [00:00&lt;00:00, 1.83MB/s]"
          },
          "model_module_version": "1.5.0"
        },
        "603ab12269b545c8b16c6cbd2a679b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        },
        "6b2745d462b24a1581247aaf087c8c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "79c51534eee347cb8061845c9598a8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e82aee461924e348ed361f0d966d230",
              "IPY_MODEL_404a3f9eb80649a49d905e38a31472df"
            ],
            "layout": "IPY_MODEL_6b2745d462b24a1581247aaf087c8c12"
          },
          "model_module_version": "1.5.0"
        },
        "81845e5c98d24f26b1e349124db910bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "9f1f543b8caf4b56ad8ebc212a4b9bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "bc21b8ed339b486ea8d7e21ad0098577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}